{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "#############\n",
    "## DATA IO ##\n",
    "#############\n",
    "\n",
    "\n",
    "def get_data(filepath):\n",
    "\n",
    "    # Opens the file handler for the dataset file. Using variable 'f' we can access and manipulate our file anywhere in our code\n",
    "    # after the next code line.\n",
    "\n",
    "    f = open(filepath, 'r')\n",
    "\n",
    "    # Predictors Collection (or your input variable) (which in this case is just the duration of eruption)\n",
    "\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    x3 = []\n",
    "    x4 = []\n",
    "\n",
    "\n",
    "    # Output Response (or your output variable) (which in this case is the duration after which next eruption will occur.)\n",
    "\n",
    "    y = []\n",
    "\n",
    "    # Initializing a reader generator using reader method from csv module. A reader generator takes each line from the file\n",
    "    # and converts it into list of columns.\n",
    "\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # Using for loop, we are able to read one row at a time.\n",
    "\n",
    "    # Iris-setosa\n",
    "    # Iris-versicolor\n",
    "    # Iris-virginica\n",
    "\n",
    "    for row in reader:\n",
    "        x1.append(float(row[0]))\n",
    "        x2.append(float(row[1]))\n",
    "        x3.append(float(row[2]))\n",
    "        x4.append(float(row[3]))\n",
    "        #print(row[3])\n",
    "        if(row[4] == 'Iris-setosa'):\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "\n",
    "    # Close the file once we have succesffuly stored all data into our X and Y variables.\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return [[\n",
    "        np.array(x1),\n",
    "        np.array(x2),\n",
    "        np.array(x3),\n",
    "        np.array(x4)\n",
    "        ], np.array(y)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(value):\n",
    "    return (1/(1+math.exp(-value)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "## RSS Calculation ##\n",
    "#####################\n",
    "\n",
    "def Cost(x, y, betas):\n",
    "    rss = 0\n",
    "    for i in range(x[0].shape[0]):\n",
    "        predicted_value = (betas[0] + (betas[1] * x[0][i]) + (betas[2] * x[1][i]) + (betas[3] * x[2][i]) + (betas[4] * x[3][i]))\n",
    "        actual_value = y[i]\n",
    "        y_ = (sigmoid(predicted_value))\n",
    "        rss = rss + ((-y*math.log(y_))-((1-y)*math.log(1-y_)))\n",
    "    return (rss/x[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(betas, x,index):\n",
    "    val = (betas[0]) + (betas[1]*x[0][index]) + (betas[2]*x[1][index]) + (betas[3]*x[2][index]) + (betas[4]*x[3][index])\n",
    "    val = sigmoid(val)\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradientDescentAlgorithm(x, y, learning_rate):\n",
    "    \n",
    "    print (\"Training Linear Regression Model using Gradient Descent\")\n",
    "    \n",
    "    maximum_iterations = 10000\n",
    "    \n",
    "    # This flag lets the program know wether the gradient descent algorithm has reached it's converged state which means wether \n",
    "    # the algorithm was able to find the local minima (where the slope of RSS wrt your parameters beta_0 and beta_1 is zero)\n",
    "    converge_status = False\n",
    "    \n",
    "    # num_rows stores the number of datapoints in the current dataset provided for training.\n",
    "    num_rows = x[0].shape[0]\n",
    "\n",
    "    # Initial Value of parameters \n",
    "    betas = [0,0,0,0,0]\n",
    "    \n",
    "    # Initial Error or RSS(beta_0,beta_1) based on the initial parameter values\n",
    "    #error = RSS(x, y, beta_0, beta_1)\n",
    "    error = Cost(x, y, betas)\n",
    "    print('Initial Value (Cost Function)=', error);\n",
    "    \n",
    "    # Iterate Loop\n",
    "    num_iter = 0\n",
    "    while not converge_status:\n",
    "        # for each training sample, compute the gradient (d/d_beta j(beta))\n",
    "        gradient_0 = 1.0/num_rows * sum([(compute_gradient(betas,x,i) - y[i]) for i in range(num_rows)]) \n",
    "        gradient_1 = 1.0/num_rows * sum([(compute_gradient(betas,x,i) - y[i])*x[0][i] for i in range(num_rows)])\n",
    "        gradient_2 = 1.0/num_rows * sum([(compute_gradient(betas,x,i) - y[i])*x[1][i] for i in range(num_rows)]) \n",
    "        gradient_3 = 1.0/num_rows * sum([(compute_gradient(betas,x,i) - y[i])*x[2][i] for i in range(num_rows)])\n",
    "        gradient_4 = 1.0/num_rows * sum([(compute_gradient(betas,x,i) - y[i])*x[3][i] for i in range(num_rows)]) \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # Computation of new parameters according to the current gradient.\n",
    "        temp0 = betas[0] - learning_rate * gradient_0\n",
    "        temp1 = betas[1] - learning_rate * gradient_1\n",
    "        temp2 = betas[2] - learning_rate * gradient_2\n",
    "        temp3 = betas[3] - learning_rate * gradient_3\n",
    "        temp4 = betas[4] - learning_rate * gradient_4\n",
    "\n",
    "    \n",
    "        # Simultaneous Update of Parameters Beta_0 and Beta_1.\n",
    "        betas[0] = temp0\n",
    "        betas[1] = temp1\n",
    "        betas[2] = temp2\n",
    "        betas[3] = temp3\n",
    "        betas[4] = temp4\n",
    "\n",
    "\n",
    "        \n",
    "        current_error = Cost(x, y, betas)\n",
    "        \n",
    "        if num_iter % 1000 == 0:\n",
    "            print ('Current Value of RSS (Cost Function) based on updated values= ', type (current_error))\n",
    "            \n",
    "        error = current_error   # update error \n",
    "        num_iter = num_iter + 1  # update iter\n",
    "    \n",
    "        if num_iter == maximum_iterations:\n",
    "            print (\"Training Interrupted as Maximum number of iterations were crossed.\\n\\n\")\n",
    "            converge_status = True\n",
    "    return [betas[0], betas[1],betas[2],betas[3],betas[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Method to predict response variable Y (in this case interval before the next erruption) for new values of X (in this case\n",
    "# duration of eruption) using the estimated coefficientsself.\n",
    "# This method can predict Response variable (Y) for single as well as multiple values of X. If only a single numerical Value\n",
    "# input variable (X) which in this case is Duration is passed. It will return the prediction for only that single numerical\n",
    "# value. If a collection of different values for input variable (list) is passed, it will return a list of predictions\n",
    "# for each input value.\n",
    "# \"if\" statement on line number 72 takes care of understanding if the input value is singular or a list.\n",
    "\n",
    "\n",
    "def predict(coef,X):\n",
    "    beta_0 = coef[0]\n",
    "    beta_1 = coef[1]\n",
    "    beta_2 = coef[2]\n",
    "    beta_3 = coef[3]\n",
    "    beta_4 = coef[4]\n",
    "\n",
    "    \n",
    "    #print(X[0])\n",
    "    \n",
    "    fy = []\n",
    "    \n",
    "    for x in X:\n",
    "        fy.append(beta_0 + (beta_1 * x[0])+ (beta_2 * x[1]) + (beta_3 * x[2]) + (beta_4 * x[3]) )\n",
    "    return fy\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression Model using Gradient Descent\n",
      "Initial Value (Cost Function)= [ 0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718\n",
      "  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718  0.69314718]\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Current Value of RSS (Cost Function) based on updated values=  <class 'numpy.ndarray'>\n",
      "Training Interrupted as Maximum number of iterations were crossed.\n",
      "\n",
      "\n",
      "total parameters:  <built-in method count of list object at 0x000002378A2B5808>\n",
      "prediction [-9.5200016652221699e-05, -9.5200016652221699e-05]\n"
     ]
    }
   ],
   "source": [
    "X,Y = get_data(\"../Dataset/iris.csv\")\n",
    "\n",
    "################################################\n",
    "## Model Training (or coefficient estimation) ##\n",
    "################################################\n",
    "# Using our gradient descent function we estimate coefficients of our regression line. The gradient descent function returns a list of \n",
    "# coefficients\n",
    "\n",
    "coefficients = gradientDescentAlgorithm(X,Y,0.000000001)\n",
    "\n",
    "########################\n",
    "## Making Predictions ##\n",
    "########################\n",
    "\n",
    "# Using our predict function and the coefficients given by our slr function we can now predict the time it will take\n",
    "# for the next eruption.\n",
    "print(\"total parameters: \",coefficients.count)\n",
    "\n",
    "\n",
    "print (\"prediction\",predict(coefficients,[[4.9,3.0,1.4,0.2],[4.9,3.0,1.4,0.2]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
